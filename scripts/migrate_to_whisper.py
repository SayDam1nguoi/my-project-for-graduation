"""
Script Tá»± Äá»™ng Migration Sang Whisper

Sá»­ dá»¥ng:
    python scripts/migrate_to_whisper.py
    python scripts/migrate_to_whisper.py --model small --backup
"""

import argparse
import sys
import shutil
from pathlib import Path
from datetime import datetime
import yaml

# Add src to path
sys.path.insert(0, str(Path(__file__).parent.parent))


def backup_config(config_path: Path) -> Path:
    """
    Backup config file.
    
    Args:
        config_path: Path to config file
        
    Returns:
        Path to backup file
    """
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    backup_path = config_path.parent / f"{config_path.stem}_backup_{timestamp}{config_path.suffix}"
    
    shutil.copy2(config_path, backup_path)
    print(f"âœ… ÄÃ£ backup config: {backup_path}")
    
    return backup_path


def update_config_for_whisper(
    config_path: Path,
    model_size: str = "small",
    beam_size: int = 8,
    enable_enhancements: bool = True,
    create_backup: bool = True
) -> bool:
    """
    Update config file to use Whisper.
    
    Args:
        config_path: Path to config file
        model_size: Whisper model size
        beam_size: Beam size for decoding
        enable_enhancements: Enable audio enhancements
        create_backup: Create backup before updating
        
    Returns:
        True if successful
    """
    try:
        # Backup if requested
        if create_backup:
            backup_config(config_path)
        
        # Load config
        with open(config_path, 'r', encoding='utf-8') as f:
            config = yaml.safe_load(f)
        
        if config is None:
            config = {}
        
        # Ensure speech_to_text section exists
        if 'speech_to_text' not in config:
            config['speech_to_text'] = {}
        
        stt_config = config['speech_to_text']
        
        # Add Whisper settings
        stt_config['model_type'] = 'whisper'
        stt_config['model_size'] = model_size
        stt_config['compute_type'] = 'int8'
        stt_config['device'] = 'cpu'
        stt_config['num_threads'] = 4
        stt_config['beam_size'] = beam_size
        stt_config['best_of'] = beam_size
        stt_config['temperature'] = [0.0, 0.2, 0.4, 0.6, 0.8, 1.0]
        stt_config['word_timestamps'] = True
        stt_config['condition_on_previous_text'] = True
        
        # Enable enhancements
        if enable_enhancements:
            stt_config['enable_audio_cleaning'] = True
            stt_config['enable_vad'] = True
            stt_config['vad_method'] = 'silero'
            stt_config['overlap_duration'] = 0.8
            stt_config['max_buffer_size'] = 15
        
        # Enable custom vocabulary if file exists
        vocab_file = Path("config/vietnamese_custom_vocabulary.json")
        if vocab_file.exists():
            stt_config['enable_vocabulary'] = True
            stt_config['vocabulary_file'] = str(vocab_file)
        
        # Performance settings
        stt_config['max_memory_mb'] = 800
        stt_config['cpu_limit_percent'] = 70.0
        stt_config['min_real_time_factor'] = 0.8
        
        # Fallback settings (keep VOSK as fallback)
        stt_config['fallback_to_vosk'] = True
        if 'vosk_model_path' not in stt_config:
            stt_config['vosk_model_path'] = 'models/vosk-model-vn-0.4'
        
        # Keep existing settings
        if 'language' not in stt_config:
            stt_config['language'] = 'vi'
        if 'sample_rate' not in stt_config:
            stt_config['sample_rate'] = 16000
        if 'chunk_duration' not in stt_config:
            stt_config['chunk_duration'] = 5.0
        if 'max_latency' not in stt_config:
            stt_config['max_latency'] = 8.0
        
        # Save updated config
        with open(config_path, 'w', encoding='utf-8') as f:
            yaml.dump(config, f, default_flow_style=False, allow_unicode=True, sort_keys=False)
        
        print(f"âœ… ÄÃ£ cáº­p nháº­t config: {config_path}")
        return True
        
    except Exception as e:
        print(f"âŒ Lá»—i khi cáº­p nháº­t config: {e}")
        return False


def check_dependencies() -> dict:
    """
    Check if required dependencies are installed.
    
    Returns:
        Dictionary with dependency status
    """
    status = {}
    
    # Check faster-whisper
    try:
        import faster_whisper
        status['faster_whisper'] = True
        print("âœ… faster-whisper Ä‘Ã£ cÃ i Ä‘áº·t")
    except ImportError:
        status['faster_whisper'] = False
        print("âŒ faster-whisper chÆ°a cÃ i Ä‘áº·t")
    
    # Check torch
    try:
        import torch
        status['torch'] = True
        print("âœ… torch Ä‘Ã£ cÃ i Ä‘áº·t")
    except ImportError:
        status['torch'] = False
        print("âš ï¸  torch chÆ°a cÃ i Ä‘áº·t (khuyáº¿n nghá»‹)")
    
    # Check noisereduce
    try:
        import noisereduce
        status['noisereduce'] = True
        print("âœ… noisereduce Ä‘Ã£ cÃ i Ä‘áº·t")
    except ImportError:
        status['noisereduce'] = False
        print("âš ï¸  noisereduce chÆ°a cÃ i Ä‘áº·t (khuyáº¿n nghá»‹)")
    
    # Check scipy
    try:
        import scipy
        status['scipy'] = True
        print("âœ… scipy Ä‘Ã£ cÃ i Ä‘áº·t")
    except ImportError:
        status['scipy'] = False
        print("âš ï¸  scipy chÆ°a cÃ i Ä‘áº·t (khuyáº¿n nghá»‹)")
    
    return status


def install_dependencies() -> bool:
    """
    Install required dependencies.
    
    Returns:
        True if successful
    """
    import subprocess
    
    print("\nğŸ“¦ Äang cÃ i Ä‘áº·t dependencies...")
    
    packages = [
        'faster-whisper',
        'torch',
        'noisereduce',
        'scipy'
    ]
    
    try:
        for package in packages:
            print(f"\nğŸ“¥ CÃ i Ä‘áº·t {package}...")
            subprocess.check_call([sys.executable, '-m', 'pip', 'install', package])
            print(f"âœ… ÄÃ£ cÃ i Ä‘áº·t {package}")
        
        print("\nâœ… ÄÃ£ cÃ i Ä‘áº·t táº¥t cáº£ dependencies")
        return True
        
    except subprocess.CalledProcessError as e:
        print(f"\nâŒ Lá»—i khi cÃ i Ä‘áº·t dependencies: {e}")
        return False


def print_summary(model_size: str, config_path: Path):
    """Print migration summary."""
    print("\n" + "=" * 80)
    print("MIGRATION HOÃ€N Táº¤T")
    print("=" * 80)
    print()
    print(f"âœ… Config Ä‘Ã£ Ä‘Æ°á»£c cáº­p nháº­t: {config_path}")
    print(f"âœ… Model size: {model_size}")
    print()
    print("ğŸ“Š Káº¿t quáº£ ká»³ vá»ng:")
    
    if model_size == "tiny":
        print("   - Äá»™ chÃ­nh xÃ¡c: 70-75%")
        print("   - Tá»‘c Ä‘á»™: Ráº¥t nhanh (4-5x real-time)")
        print("   - RAM: 1-2 GB")
    elif model_size == "base":
        print("   - Äá»™ chÃ­nh xÃ¡c: 85-90%")
        print("   - Tá»‘c Ä‘á»™: Nhanh (2-3x real-time)")
        print("   - RAM: 2-3 GB")
    elif model_size == "small":
        print("   - Äá»™ chÃ­nh xÃ¡c: 90-93% â­ Khuyáº¿n nghá»‹")
        print("   - Tá»‘c Ä‘á»™: Trung bÃ¬nh (1.5-2x real-time)")
        print("   - RAM: 3-4 GB")
    elif model_size == "medium":
        print("   - Äá»™ chÃ­nh xÃ¡c: 93-95%")
        print("   - Tá»‘c Ä‘á»™: Cháº­m (2-3x real-time)")
        print("   - RAM: 5-6 GB")
    elif model_size == "large":
        print("   - Äá»™ chÃ­nh xÃ¡c: 95-97%")
        print("   - Tá»‘c Ä‘á»™: Ráº¥t cháº­m (3-4x real-time)")
        print("   - RAM: 9-10 GB")
    
    print()
    print("ğŸš€ BÆ°á»›c tiáº¿p theo:")
    print("   1. Cháº¡y test: python scripts/test_stt_accuracy.py")
    print(f"   2. Cháº¡y app: python launcher.py --config {config_path}")
    print("   3. Kiá»ƒm tra log: logs/speech_analysis.log")
    print()
    print("ğŸ“š TÃ i liá»‡u:")
    print("   - docs/MIGRATION_TO_WHISPER.md")
    print("   - docs/VIETNAMESE_STT_ACCURACY_GUIDE.md")
    print()
    print("=" * 80)


def main():
    """Main function."""
    parser = argparse.ArgumentParser(
        description="Migration Script: Chuyá»ƒn tá»« VOSK sang Whisper"
    )
    parser.add_argument(
        '--config',
        type=str,
        default='config/speech_config.yaml',
        help='Path to config file (default: config/speech_config.yaml)'
    )
    parser.add_argument(
        '--model',
        type=str,
        default='small',
        choices=['tiny', 'base', 'small', 'medium', 'large'],
        help='Whisper model size (default: small)'
    )
    parser.add_argument(
        '--beam-size',
        type=int,
        default=8,
        help='Beam size for decoding (default: 8)'
    )
    parser.add_argument(
        '--no-backup',
        action='store_true',
        help='Do not create backup of config file'
    )
    parser.add_argument(
        '--no-enhancements',
        action='store_true',
        help='Do not enable audio enhancements'
    )
    parser.add_argument(
        '--install-deps',
        action='store_true',
        help='Install required dependencies'
    )
    parser.add_argument(
        '--check-only',
        action='store_true',
        help='Only check dependencies, do not update config'
    )
    
    args = parser.parse_args()
    
    print("=" * 80)
    print("MIGRATION SCRIPT: VOSK â†’ WHISPER")
    print("=" * 80)
    print()
    
    # Check dependencies
    print("ğŸ” Kiá»ƒm tra dependencies...")
    print()
    deps_status = check_dependencies()
    print()
    
    # If check-only mode, exit here
    if args.check_only:
        if not deps_status['faster_whisper']:
            print("âš ï¸  Cáº§n cÃ i Ä‘áº·t faster-whisper:")
            print("   pip install faster-whisper")
        return
    
    # Install dependencies if requested
    if args.install_deps:
        if not install_dependencies():
            print("\nâŒ KhÃ´ng thá»ƒ cÃ i Ä‘áº·t dependencies. Vui lÃ²ng cÃ i thá»§ cÃ´ng:")
            print("   pip install faster-whisper torch noisereduce scipy")
            return
        print()
    
    # Check if faster-whisper is installed
    if not deps_status['faster_whisper']:
        print("âŒ faster-whisper chÆ°a Ä‘Æ°á»£c cÃ i Ä‘áº·t!")
        print()
        print("Vui lÃ²ng cÃ i Ä‘áº·t:")
        print("   pip install faster-whisper")
        print()
        print("Hoáº·c cháº¡y vá»›i --install-deps:")
        print(f"   python {sys.argv[0]} --install-deps")
        return
    
    # Update config
    config_path = Path(args.config)
    
    if not config_path.exists():
        print(f"âŒ Config file khÃ´ng tá»“n táº¡i: {config_path}")
        return
    
    print(f"ğŸ“ Äang cáº­p nháº­t config: {config_path}")
    print(f"   Model size: {args.model}")
    print(f"   Beam size: {args.beam_size}")
    print(f"   Audio enhancements: {not args.no_enhancements}")
    print(f"   Create backup: {not args.no_backup}")
    print()
    
    success = update_config_for_whisper(
        config_path=config_path,
        model_size=args.model,
        beam_size=args.beam_size,
        enable_enhancements=not args.no_enhancements,
        create_backup=not args.no_backup
    )
    
    if success:
        print_summary(args.model, config_path)
    else:
        print("\nâŒ Migration tháº¥t báº¡i!")
        print("Vui lÃ²ng kiá»ƒm tra lá»—i vÃ  thá»­ láº¡i.")


if __name__ == "__main__":
    main()

